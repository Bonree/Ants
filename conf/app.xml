<?xml version="1.0" encoding="UTF-8"?>
<!-- 规范说明 begin -->
<!-- 1.标签名和属性名统一使用小写字母（不能用小写字母的地方请做出说明） -->
<!-- 2.标签名和属性名的单词之间的分隔符统一用点“.” (不能用“.”分隔的地方请做出说明) -->
<!-- 3.配置项只有单个值（value属性后面直接以反斜杠“/”结束，详细见example示例） -->
<!-- 规范说明 end -->

<!-- 引擎配置信息, namespace表示命名空间 -->
<ants namespace="apms">
    <!-- example begin -->
    <example>
        <!-- 配置项只有单个值（value属性后面直接以反斜杠“/”结束） -->
        <property name="what.is.your.name" value="bonree"/>
        <!-- 配置项有多个值 -->
        <property name="multi.value">
            <list>
                <value>1</value>
                <value>2</value>
            </list>
        </property>
    </example>
    <!-- example end -->

    <!-- 1.zookeeper集群信息 -->
    <zookeeper>
        <property name="zookeeper.cluster">
            <list>
                <value>Dev-SDK-StormFlow01:2181</value>
                <value>Dev-SDKStormFlow02:2181</value>
                <value>Dev-SDKStormFlow03:2181</value>
            </list>
        </property>
    </zookeeper>

    <!-- 2.Kafka集群信息 -->
    <kafka>
        <property name="kafka.cluster">
            <list>
                <value>Dev-SDK-StormFlow01:9092</value>
                <value>Dev-SDKStormFlow02:9092</value>
                <value>Dev-SDKStormFlow03:9092</value>
            </list>
        </property>
        <!-- topic是否使用命名空间, 只针对 source.topic 属性生效 -->
        <property name="source.topic.use.namespace" value="true"/>
        <!-- 订阅数据的groupId, 只针对 source.topic 属性生效-->
        <property name="group.id" value="apms_data_group"/>
        <!-- STORM订阅源数据的topic -->
        <property name="source.topic" value="apms_sdk_topic"/>
        <!-- STORM计算结果的报警消息topic -->
        <property name="alert.result.topic" value="alert_topic"/>
    </kafka>

    <!-- 3.redis集群信息 -->
    <redis>
        <!-- redis集群信息 -->
        <property name="redis.cluster">
            <list>
                <value>Dev-SDK-StormFlow01:7000</value>
                <value>Dev-SDK-StormFlow01:7001</value>
                <value>Dev-SDK-StormFlow01:7002</value>
                <value>Dev-SDK-StormFlow01:7003</value>
                <value>Dev-SDK-StormFlow01:7004</value>
                <value>Dev-SDK-StormFlow01:7005</value>
            </list>
        </property>
    </redis>

    <!-- 4.db连接驱动 -->
    <db>
        <property name="driver.class" value="com.mysql.jdbc.Driver"/>
        <property name="url"
                  value="jdbc:mysql://*.*.*.*:30092/test?rewriteBatchedStatements=true&amp;useUnicode=true&amp;characterEncoding=UTF8&amp;zeroDateTimeBehavior=convertToNull"/>
        <property name="username" value="******"/>
        <property name="password" value="******"/>
    </db>

    <!-- 5.etl插件配置 放app.xml里 -->
    <etl-plugin>
        <!-- ETL插件所在的路径(包含jar名称), 此目录为相对目录, 根目录是${ANTS_HOME}/pluign -->
        <property name="etl.plugin.path" value="/etl/Plugin-Impl.jar"/>
        <!-- ETL插件jar实现接口的完整包路径(包含实现类名称) -->
        <property name="etl.service.impl" value="com.bonree.plugin.EtlService"/>
    </etl-plugin>

    <!-- 6.自定义函数计算插件配置, use为false时数据不使用插件,为true时开启插件计算 -->
    <!-- use为false时schema.xml中不可以使用udf函数,为true时schema.xml中可以使用udf函数 -->
    <operator-plugin use="true">
        <!-- operator插件所在的路径(包含jar名称), 此目录为相对目录, 根目录是${ANTS_HOME}/pluign-->
        <property name="operator.plugin.path" value="/operator/Plugin-Impl.jar"/>
        <!-- operator插件jar实现接口的完整包路径(包含实现类名称) -->
        <property name="operator.service.impl" value="com.bonree.plugin.OperatorServiceImpl"/>
    </operator-plugin>

    <!-- 汇总数据存储插件配置, topic为汇总结果在kafka上的topic名称; use为false时数据默认入mysql数据库,为true时数据交给插件处理 -->
    <default-storage-plugin topic="result_topic,resultday_topic" use="false">
        <!-- storage插件所在的路径(包含jar名称), 此目录为相对目录, 根目录是${ANTS_HOME}/pluign -->
        <property name="storage.plugin.path" value="/storage/Plugin-Impl.jar"/>
        <!-- storage插件jar实现接口的完整包路径(包含实现类名称) -->
        <property name="storage.service.impl" value="com.bonree.plugin.StorageServiceImpl"/>
    </default-storage-plugin>

    <!-- 自定义数据存储插件配置(日志轨迹), topic为自定义数据在kafka上的topic名称; -->
    <!-- 注：此topic是启动存储拓扑时的参数; 如有多类自定义数据时，此标签可配置多对，topic不一样即可-->
    <custom-storage-plugin topic="records_topic">
        <!-- storage插件所在的路径(包含jar名称), 此目录为相对目录, 根目录是${ANTS_HOME}/pluign -->
        <property name="storage.plugin.path" value="/storage/Plugin-Impl.jar"/>
        <!-- storage插件jar实现接口的完整包路径(包含实现类名称) -->
        <property name="storage.service.impl" value="com.bonree.plugin.StorageServiceImpl"/>
    </custom-storage-plugin>

    <!-- 自定义数据存储插件配置(快照), topic为自定义数据在kafka上的topic名称; -->
    <!-- 注：此topic是启动存储拓扑时的参数; 如有多类自定义数据时，此标签可配置多对，topic不一样即可-->
    <custom-storage-plugin topic="snapshot_topic">
        <!-- storage插件所在的路径(包含jar名称), 此目录为相对目录, 根目录是${ANTS_HOME}/pluign -->
        <property name="storage.plugin.path" value="/storage/Plugin-Impl.jar"/>
        <!-- storage插件jar实现接口的完整包路径(包含实现类名称) -->
        <property name="storage.service.impl" value="com.bonree.plugin.StorageServiceImpl"/>
    </custom-storage-plugin>

    <!-- 8.引擎公共配置,计算,基线,报警都会用到 -->
    <global>
        <!-- 根路径,用于管理引擎中的插件或错误文件 -->
        <property name="root.path" value="/data/"/>
        <!-- storm集群计算节点的数量 -->
        <property name="storm.supervisor.count" value="2"/>
        <!-- 保存计算中间结果到redis的单个数据包条数 -->
        <property name="redis.batch.count" value="40000"/>
        <!-- 发送计算结果数据到kafka的单个数据包条数 -->
        <property name="kafka.batch.count" value="3000"/>
        <!-- 处理原始数据包的粒度,单位:秒 -->
        <property name="source.granule" value="1"/>
    </global>

    <!-- 9. 计算引擎配置-->
    <calc>
        <!-- 处理原始数据计算时的worker内存 -->
        <property name="preprocessing.memory" value="-Xmx1g -Xms1g"/>
        <!-- 处理粒度汇总数据时的worker内存 -->
        <property name="granule.memory" value="-Xmx1g -Xms1g"/>
        <!-- 处理大粒度汇总数据时的worker内存 -->
        <property name="big.granule.memory" value="-Xmx1g -Xms1g"/>
        <!-- 数据汇总的粒度(取值范围:60-86400),单位:秒 注:1.分钟粒度要是1小时内的整数倍, 2.小时粒度要是整小时的倍数, 3.后面的粒度要是前面的整数倍,-->
        <property name="granule" value="60,600,3600,21600,86400"/>
        <!-- 保存计算中间结果在redis中的的分桶数量 -->
        <property name="redis.bucket.count" value="2,4,6,8,8"/>
        <!-- 粒度汇总时,并行计算的节点倍数,公式: storm.supervisor.count * granule.calc.parallel = redis.bucket.count -->
        <property name="granule.calc.parallel" value="1,2,3,1,1"/>
        <!-- 粒度汇总超时时间,分别与granule的值一一对应,单位:分钟 -->
        <property name="granule.timeout" value="2,5,20,60,90"/>
        <!-- 分隔粒度汇总拓扑的位置(只可分隔成2个拓扑),取值为granule属性值,默认取前2个为小粒度拓扑,后面的为大粒度拓扑-->
        <property name="split.granule.number" value="2"/>
        <!-- 汇总时的结果不需要存储的粒度,多个以","分隔,取值为granule属性的值-->
        <property name="skip.storage.granule" value="21600"/>
        <!-- 数据整体延迟汇总的时间,单位毫秒 -->
        <property name="delay.calc.time" value="60000"/>
        <!-- 原始数据计算时频率,单位:毫秒 -->
        <property name="calc.preprocessing.interval" value="1000"/>
        <!-- 粒度汇总时频率,单位:毫秒 -->
        <property name="calc.granule.interval" value="1000"/>
        <!-- 大粒度粒度汇总时频率,单位:毫秒 -->
        <property name="calc.big.granule.interval" value="2000"/>
        <!-- 订阅业务KAFKA单条消息的最大限制(bytes) -->
        <property name="msg.max.bytes" value="10485760"/>
        <!-- 订阅业务KAFKA单条消息的最大限制(bytes) -->
        <property name="msg.max.bytes" value="10485760"/>
        <!-- 每次拉取kafka数据时的最大拉取条数限制 -->
        <property name="max.poll.count" value="200"/>
        <!-- 预处理拓扑启动参数: wn:worker数量,默认为storm.supervisor.count; spn:spout并发数(可选); sn:预处理数据线程数(可选); gn:全局分组汇总数据线程数(可选). -->
        <!-- 多个参数以空格分隔-->
        <property name="preprocessing.startup.params" value=""/>
        <!-- 粒度汇总启动参数: wn:worker数量,默认为storm.supervisor.count; an: 汇总数据线程数.(可选) -->
        <!-- 多个参数以空格分隔-->
        <property name="granule.startup.params" value=""/>
    </calc>

    <!-- 10.基线和报警引擎配置 -->
    <baseline>
        <!-- 处理基线数据计算时的worker内存 -->
        <property name="baseline.memory" value="-Xmx1g -Xms1g"/>
        <!-- 处理报警数据计算时的worker内存 -->
        <property name="alert.memory" value="-Xmx1g -Xms1g"/>
        <!-- 基线数据汇总时的频率,单位:毫秒 -->
        <property name="calc.baseline.interval" value="500"/>
        <!-- 报警数据汇总时的频率,单位:毫秒 -->
        <property name="calc.alert.interval" value="1000"/>
        <!-- 基线数据基线数据保留的时长(也是报警数据对比的周期),单位:天 -->
        <property name="baseline.cycle" value="7"/>
        <!-- 基线数据汇总的粒度,单位:秒 -->
        <property name="granule" value="60,300"/>
        <!-- 保存基线计算中间结果在redis中的的分桶数量 -->
        <property name="redis.bucket.count" value="4,4"/>
        <!-- 基线粒度汇总时,并行计算的节点倍数,默认为1倍,公式: storm.supervisor.count * granule.calc.parallel = redis.bucket.count -->
        <property name="granule.calc.parallel" value="2,2"/>
        <!-- 基线粒度汇总超时时间,分别与granule的值一一对应,单位:分钟 -->
        <property name="granule.timeout" value="2,5"/>
        <!-- 基线汇总时的结果不需要存储的粒度,多个以","分隔,取值为granule属性的值-->
        <property name="skip.storage.granule" value="300"/>
        <!-- 发送和订阅业务KAFKA单条消息的最大限制(bytes) -->
        <property name="msg.max.bytes" value="10485760"/>
        <!-- 启动参数: wn:worker数量,默认为storm.supervisor.count; an:汇总数据线程数(可选). -->
        <!-- 多个参数以空格分隔-->
        <property name="baseline.startup.params" value=""/>
        <!-- 启动参数: wn:worker数量,默认为storm.supervisor.count; an:汇总数据线程数(可选); -->
        <!-- 多个参数以空格分隔-->
        <property name="alert.startup.params" value=""/>
    </baseline>

    <!-- 11.存储引擎配置 -->
    <storage>
        <!-- 处理入库数据时的worker内存 -->
        <property name="storage.memory" value="-Xmx1g -Xms1g"/>
        <!-- 订阅业务KAFKA单条消息的最大限制(bytes) -->
        <property name="msg.max.bytes" value="10485760"/>
        <!-- 每次拉取kafka数据时的最大拉取条数限制 -->
        <property name="max.poll.count" value="10"/>
        <!-- 启动参数: wn:worker数量,默认为storm.supervisor.count; spn:spout并发数(可选); sn:处理数据线程数(可选); -->
        <!-- 多个参数以空格分隔-->
        <property name="storage.startup.params" value=""/>
    </storage>

    <!-- 13.数据库连接池, 如果app.xml中配置了storage插件,刚此配置不生效 -->
    <pool>
        <!--当连接池用完时客户端调用getConnection()后等待获取新连接的时间，超时后将抛出SQLException,如设为0则无限期等待。单位毫秒。Default:0 -->
        <property name="checkout.timeout" value="60000"/>
        <!--maxStatementsPerConnection定义了连接池内单个连接所拥有的最大缓存statements数。Default:0 -->
        <property name="max.statements.per.connection" value="20"/>
        <!--初始化时获取三个连接，取值应在minPoolSize与maxPoolSize之间。Default: 3 -->
        <property name="initial.pool.size" value="2"/>
        <!--最大空闲时间,60秒内未使用则连接被丢弃。若为0则永不丢弃。Default: 0 -->
        <property name="max.idle.time" value="60"/>
        <!--连接池中保留的最大连接数。Default: 15 -->
        <property name="max.pool.size" value="20"/>
        <!--连接池中保留的最小连接数。Default: 3 -->
        <property name="min.pool.size" value="1"/>
        <!--当连接池中的连接耗尽的时候c3p0一次同时获取的连接数。Default: 3 -->
        <property name="acquire.increment" value="1"/>
        <!--每多少秒检查所有连接池中的空闲连接。Default: 0 ， 业务每次获取时判断连接是否可以，这项设置为0 -->
        <property name="idle.connection.test.period" value="60"/>
        <!--c3p0是异步操作的，缓慢的JDBC操作通过帮助进程完成。扩展这些操作可以有效的提升性能通过多线程实现多个操作同时被执行。Default:3 -->
        <property name="num.helper.threads" value="3"/>
        <!--定义所有连接测试都执行的测试语句。在使用连接测试的情况下这个一显著提高测试速度。注意：测试的表必须在初始数据源的时候就存在。Default:null -->
        <property name="preferred.test.query" value="select 1"/>
        <!-- 延后清理statement缓存线程数 -->
        <property name="statement.cache.num.deferred.close.threads" value="1"/>
        <!-- 强制关闭连接(s) -->
        <property name="unreturned.connection.timeout" value="300"/>
    </pool>

</ants>